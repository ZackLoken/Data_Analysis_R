---
title: ""
author: "Zack Loken"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = "CENTER", fig.width = 14)
```

<center> <h1>__Zack Loken - OCS 7131 Assignment 3__</h1> </center>
<br>

### __Concepts__

##### 1. Write a short paragraph about how to conceptualize a linear model, and use the terms: *units*, *predictors*, *response*, *linear predictor*, and *error*. 
  
  + Before conceptualizing a linear model, it is important to understand these terms: *units*, *predictors*, *response*, *linear predictor*, and *error*. The *Units* are the individual observations and are often indexed with *i*. The *Predictors*, or independent (x) variables, are the variables that are included on the right side of the model equation---they provide information regarding particular outcomes for the response (dependent) variable and can be either continuous or categorical. The *Response* variable, or the dependent (y) variable, is typically the single term on the left side of the model equation---it responds to the *predictors* and is a continuous variable whose variation is measured according to the terms on the right side of the model equation. The *linear predictors* refer to the deterministic part on the right side of the model equation---the part of the equation where the *predictors* and their parameters are represented. Finally, and because the *predictors* will never explain 100% of the *response* variables variation, the *error* (residual) is the other component (stochastic) to the right side of the model equation---it regards the the unexplained information not captured by the *predictors*. Therefore, it is easiest to consider the components of the linear model as __$response = linear.predictors + error$__.
<br>

##### 2. Why is it important to understand the data-generating distribution (the assumed distribution of your data) as you go about selecting the appropriate model? 

  + It is important to understand the assumed distribution of your data as you go about selecting the appropriate model because each model (e.g., linear regression) assumes the model coefficients to follow a certain distribution. In linear regression, for example, it is assumed that the variance of the residuals are normally distributed with a mean centered around zero. If model coefficients don't follow the assumed distribution of a particular chosen model, it is an indicator of poor model fit for the data of interest---a new model should be chosen to better fit the data.
<br>

##### 3. What is the difference between a means and an effects parameterization? Answer in terms of the model matrix and the result. 

  + In an effects parameterization (y ~ x), which is the default in R, the intercept estimate is always the mean of group 1---but it is also the baseline estimate that all other groups need to be combined with. Another way to interpret an effects parameterization is that the estimate for every group after the first one can be thought of as the effect of being in that group compared to group 1. The other type of parameterization, a means parameterization (y ~ x - 1), simply tells you that each group is given its own mean. Another way to look at it is that the model has (sort of) already combined the effects and is giving you the group-specific information that does not need to be referenced back to any other group. In terms of the model matrix and outputs for an effects parameterization, all observations are included in the intercept and then each group's observations are included in their own respective columns. In terms of the model matrix and outputs for a means parameterization, however, only those observation values belonging to specific groups are included (no intercept column).
<br>

### __Linear Model__

##### 4. Using the built-in dataset `trees`, write a linear model that evaluates the effect of `Height` on `Volume`. 
```{r}
data("trees")

Height <- trees$Height
Volume <- trees$Volume

Q4 <- lm(Volume ~ Height)
```
<br>

##### 5. Describe how you evaluated the residuals and what your determination is about the residuals.
  
  + See below for code example describing how I evaluated the residuals. Based on the residuals plot, which is roughly symmetrical and somewhat centered around 0, it can be determined that the model's predictions are on slightly off by a median value of -2.894. A simple linear regression model is therefore suitable for this data. However, the low adjusted R-squared value (0.3358) suggests that the model is not a good fit.
```{r}
# Evaluate the residuals and any reported significance. 
summary.lm(Q4)

# Plot the residuals to see if they are close to being centered over 0 w/ roughly symmetric shape. 
resQ4 <- resid(Q4)
hist(resQ4, breaks = 10, las = 1, col = 1, border = "white", xlab = "Residual", main = '')
```
<br>

##### 6. Try `Girth` instead of `Height` as the independent variable. Is `Girth` a better predictor than `Height`? Include how you interpret one predictor being better than another.

  + Yes, `Girth` is a better predictor than `Height`. The residuals can be compared between models to see which independent variable is the better predictor. `Girth` had a minimum residual value of -8.065, a median residual value of 0.152, and a maximum residual value of 9.587. `Height` had a minimum residual value of -21.274, a median residual value of -2.894, and a maximum residual value of 29.852. Because the residual values for `Height` are greater than (which indicates worse predictor capability) those for `Girth`, it can be determined that `Girth` is the better predictor on tree `Volume`.
```{r}
Girth <- trees$Girth

Q5 <- lm(Volume ~ Girth)

summary.lm(Q5)

resQ5 <- resid(Q5)
hist(resQ5, breaks = 10, las = 1, col = 1, border = "white", xlab = "Residual", main = '')
```
<br>

### __Generalized Linear Model__

##### 7. List 3 examples in your field of study where GLMs might be applicable. (This can be common data collected or common relationships in your research area). In order to get full credit for each example, include the specific type of GLM and why you selected that one. 

  + Example 1) Using species presence-absence data as a response, combined with various habitat metrics as predictor variables, to perform habitat suitability modeling. The specific type of GLM that I've seen most commonly used for predicting species occurrence based on habitat suitability is binomial, because presence-absence data is binomial (0 = absence, 1 = presence). [Example 1 Reference Paper](https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2664.2010.01781.x).  

  + Example 2) Using species count data as a response, combined with various landscape metrics as predictor variables, to estimate species distribution. The specific type of GLM that I've seen most commonly used for estimating species distribution in a discrete geographical space is Poisson, because count data cannot be negative and are (usually) integers. [Example 2 Reference Paper](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210X.2011.00141.x).  

  + Example 3) Using nest presence-absence data as a response, combined with various environmental parameters as predictor variables, to predict likelihood of a duck nest being present. The specific type of GLM used for this analysis is binomial, because presence-absence data is binomial (0 = absence, 1 = presence).
  <br>

##### 8. You run a Poisson GLM and then (separately) an LM on a dataset with the response of species richness. Both models fit and the regression lines do not clearly suggest which is the better model. Which one do you use, and why?

  + In the case of both models fitting and their regression lines not clearly suggesting which is the better model, I would opt for the Poisson GLM because it doesn't assume the residuals to follow a normal distribution (like the LM does) and count data is generally best suited for a Poisson distribution due to the values being greater than or equal to 0 and whole numbers only. 
<br>

##### 9. In the `Stat2Data` library, load the `LeveeFailures` data. Write a model for a GLM to evaluate the effect of `Sinuosity` on `Failure`. 
```{r}
library(Stat2Data)

data("LeveeFailures")

# Write a binomial GLM to evaluate the effect of sinuosity on failure
# failure is a binomial response variable
Q9.glm <- glm(LeveeFailures$Failure ~ LeveeFailures$Sinuosity, family = binomial)
Q9.glm
```
<br>

##### 10. What is the sinuosity at which you have a 50% probability levee failure? 

  + There will be a 50% probability of levee failure when sinuosity is equal to 1.683.
```{r}
# Inflection point (i.e., p(50))
# Divide the negative intercept by the slope coefficient
-coef(Q9.glm)[1]/coef(Q9.glm)[2]
```
<br>
geom_point(x = 1.683, y = 0.5, aes(color = "red")) +
##### 11. Plot the data and the model. 
```{r}
library(tidyverse)

summary(Q9.glm)

ggplot(LeveeFailures, aes(x = LeveeFailures$Sinuosity, y = LeveeFailures$Failure)) +
  geom_jitter(width = 0.01, height = 0.01) +
  xlab("Sinuosity") +
  ylab("Levee Failure Probability") +
  theme_classic(base_size = 15) +
  theme(legend.position = "none") + 
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  geom_point(x = 1.683, y = 0.5, size = 5, aes(color = "red"))
```
<br>

### __Random Effects and Mixed Models__

##### 12. List 3 examples in your field where random effects (or mixed models) might be applicable. (This can be common data collected or common relationships examined in your research area). In order to get full credit for each example, include the specific attribute(s) of the data that qualify it as such.

  + Example 1) When modeling abundance of a species in response to a range of habitat metrics, region could be used as a random effect to control for spatial autocorrelation. Region is a suitable random effect variable because the intended scope of inference is likely to extend beyond the scope of the study. Furthermore, both the individual region and the relationship between species abundance and habitat metrics can be viewed as a random sample from a probability distribution.  
  
  + Example 2) When modeling surface water area as a response to a range of climate metrics, wetland type could be used as a random effect. Wetland type is a suitable random effect variable because the intended scope of inference is likely to extend beyond the factor levels (i.e., wetland types) included in the study to the entire population of wetland types. Furthermore, both the individual region and the relationship between species abundance and habitat metrics can be viewed as a random sample from a probability distribution.  
  
  + Example 3) When modeling nest presence-absence data as a response to various habitat parameters as predictor variables, habitat type could be used as a random effect. Habitat type is a suitable random effect variable because the intended scope of inference could extend beyond the factor levels (i.e., habitat types) included in the study to all habitat types. Furthermore, both the individual habitat type and the relationship between nest presence and habitat parameters can be viewed as a random sample from a probability distribution. 
<br>

##### 13. Explain one admonition each for aggregating and disaggregating data. 

  + Aggregating: When you aggregate the data, each factor level (e.g., species) is distilled into one observation (so your sample size decreases). This approach ignores within-group variation, which is risky because it may be a large part of the overall variance---thus resulting in a loss of information and power. Another way to view aggregating data is that it is really modeling the means of each factor level - each sample becomes a subsample.   
  
  + Disaggregating: When you disaggregate data, the factor levels (groups) are excluded but all observations remain (sample size doesn't change). This approach erroneously considers each observation as an independent replicate sample, which is unlikely true because within-group measurements are more likely to be more similar than when compared to other groups. Furthermore, factor levels with large sample sizes would contribute disproportionately to the coefficients even though factor levels are not included. 
<br>

##### 14. In the `Stat2Data` library, load the `Sparrows` data. Write a mixed model for the effect of `WingLength` on `Weight` that includes only a random slope.
```{r}
library(lme4)

data("Sparrows")

# Mixed model with random slope and fixed intercept
mix.sl <- lmer(Weight ~ WingLength + (0 + WingLength | Treatment), data = Sparrows)
summary(mix.sl)
```
<br>

##### 15. Is there evidence supporting a different relationship between `WingLength` on `Weight` by `Treatment`?

  + Because this is a random slope mixed model, the mean coefficients for `Treatment` should vary. We can check the coefficients of the random effect (`Treatment`) to see by how much they vary---the reduced group has a mean `WingLength` of 0.479, the control group has a mean `WingLength` of 0.453, and the enlarged group has a mean `WingLength` of 0.436. Although the means only vary slightly, it is worth running a *post-hoc* multiple comparisons test to see whether this variation is significant.
```{r}
# Check the coefficients for mean differences among treatment groups
coef(mix.sl)$Treatment
```
<br>

##### 16. Using a multipanel plot, show `Treatment`-specific relationships of the model in question 14. 
```{r}
library(tidyverse)

# Isolate coefficients from mixed model
mix.sl.coef <- coef(mix.sl)$Treatment %>%
  rename(Intercept = '(Intercept)', Slope = WingLength) %>%
  rownames_to_column ("Treatment")

mix.sl.coef.join <- left_join(Sparrows, mix.sl.coef, by = "Treatment")

ggplot(mix.sl.coef.join, aes(y = Weight, x = WingLength)) +
  geom_point() +
  xlab("Wing Length") +
  ylab("Weight") +
  theme_classic(base_size = 15) +
  geom_abline(aes(intercept = Intercept, slope = Slope, color = Treatment)) +
  labs(color = "Treatment") +
  facet_wrap(~Treatment)
```
<br>

##### 17. Examine the relationship in question 14 with a random intercepts model. Provide one reason why this may be a better model and one reason why this may not be a better model.

  + The random intercepts mixed model may be a better model because it allows the response variable estimate for each observation to be predicted by intercepts that vary across `Treatment` levels, but may not be a better model because it doesn't allow the predictor to have a different effect for each `Treatment` level (which is supported by the very low ICC of 0.192).
```{r}
# Mixed model with fixed slope and random intercept
mix.int <- lmer(Weight ~ WingLength + (1 | Treatment), data = Sparrows)
summary(mix.int)
coef(mix.int)$Treatment

# ICC from random intercepts fixed slope model by calculating random intercept variance divided by total variance. 
mix.int.icc <- 0.4111 / (1.7304 + 0.4111)
mix.int.icc
```
<br>

